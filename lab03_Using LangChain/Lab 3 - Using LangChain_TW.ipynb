{"cells":[{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"}},"source":["![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n","# 使用watsonx, 和 LangChain 對語言模型進行一系列調用"]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"}},"source":["#### 聲明\n","\n","- 僅使用在watsonx可用的項目和空間。\n","\n","\n","## Notebook内容\n","\n","這篇notebook包含步驟和程式碼，支援透過watsonx模型和langchain整合來示範Simple Sequential Chain。對於Python有一定的熟練度會有幫助。這篇notebook使用Pythong 3.10。\n","\n","\n","## 學習目標\n","\n","這篇notebook的目標是示範串聯`google/flan-ul2`和`google/flan-t5-xxl`模型來產生一系列關於給定主題的隨機問題和該問題的答案，讓使用者熟悉LangChain框架，使用WatsonxLLM, 簡單鏈(LLMChain) 和擴充鏈(SimpleSequentialChain)。\n","\n","\n","## 内容\n","\n","這篇notebook包含下列部分：\n","\n","- [環境配置](#setup)\n","- [watsonx基礎模型](#models)\n","- [LangChain 串接](#watsonxllm)\n","- [Simple Sequential Chain實驗](#experiment)\n","- [總結](#summary)"]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"}},"source":["<a id=\"setup\"></a>\n","## 配置環境\n","\n","在開始使用notebook的範例程式碼之前，需要完成下列設定任務：\n","\n","-  連接一個 <a href=\"https://console.ng.bluemix.net/catalog/services/ibm-watson-machine-learning/\" target=\"_blank\" rel=\"noopener no referrer\">Watson Machine Learning (WML) 實例</a> instance (關於如何建立實例的信息 <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/ml-service-instance.html?context=analytics\" target=\"_blank\" rel=\"noopener no referrer\">here</a>)."]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"}},"source":["### 安裝並匯入 `datasets` 和依賴套件"]},{"cell_type":"code","execution_count":2,"metadata":{"pycharm":{"is_executing":true,"name":"#%%\n"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Successfully installed ibm-watson-machine-learning-1.0.327\n","Successfully installed annotated-types-0.6.0 pydantic-2.4.2 pydantic-core-2.10.1 typing-extensions-4.8.0\n","Successfully installed anyio-3.7.1 dataclasses-json-0.6.1 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.331 langsmith-0.0.60 marshmallow-3.20.1 sniffio-1.3.0 typing-inspect-0.9.0\n"]}],"source":["!pip install \"ibm-watson-machine-learning>=1.0.327\" | tail -n 1\n","!pip install \"pydantic>=1.10.0\" | tail -n 1\n","!pip install langchain | tail -n 1"]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"}},"source":["### 定義 WML credentials\n","這個單元定義使用watsonx基礎模型推理所需的WML credentials。\n","\n","**操作:** 提供IBM Cloud用戶API Key，詳情參考\n","[文檔](https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui)。"]},{"cell_type":"code","execution_count":1,"metadata":{"pycharm":{"name":"#%%\n"}},"outputs":[],"source":["import getpass\n","\n","credentials = {\n","    \"url\": \"https://us-south.ml.cloud.ibm.com\",\n","    \"apikey\": getpass.getpass(\"Please enter your WML api key (hit enter): \")\n","}"]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"}},"source":["### 定義 project id\n","基礎模型需要project id，用於提供模型呼叫上下文資訊。我們將從運行此筆記本的項目中獲取id。否則，請另外提供project id。"]},{"cell_type":"code","execution_count":2,"metadata":{"pycharm":{"name":"#%%\n"}},"outputs":[],"source":["import os\n","\n","try:\n","    project_id = os.environ[\"PROJECT_ID\"]\n","except KeyError:\n","    project_id = input(\"Please enter your project_id (hit enter): \")"]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"}},"source":["<a id=\"models\"></a>\n","## `watsonx.ai`的基礎模型"]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"}},"source":["#### 列出可用的模型\n","\n","所有可用的模型都顯示在ModelTypes類別下。\n","更多資訊可參考 [documentation](https://ibm.github.io/watson-machine-learning-sdk/foundation_models.html#ibm_watson_machine_learning.foundation_models.utils.enums.ModelTypes)."]},{"cell_type":"code","execution_count":3,"metadata":{"pycharm":{"name":"#%%\n"}},"outputs":[{"name":"stdout","output_type":"stream","text":["['FLAN_T5_XXL', 'FLAN_UL2', 'MT0_XXL', 'GPT_NEOX', 'MPT_7B_INSTRUCT2', 'STARCODER', 'LLAMA_2_70B_CHAT', 'GRANITE_13B_INSTRUCT', 'GRANITE_13B_CHAT']\n"]}],"source":["from ibm_watson_machine_learning.foundation_models.utils.enums import ModelTypes\n","\n","print([model.name for model in ModelTypes])"]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"}},"source":["需要定義用於模型推理的 `model_id`:"]},{"cell_type":"code","execution_count":4,"metadata":{"pycharm":{"name":"#%%\n"}},"outputs":[],"source":["model_id_1 = ModelTypes.FLAN_UL2\n","model_id_2 = ModelTypes.FLAN_T5_XXL"]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"}},"source":["### 定義模型參數\n","\n","可能需要調整模型 `parameters` 用於不同的模型和任務, 具體可參考 `GenTextParamsMetaNames` 類別.\n","\n","**操作:** 詳細API可參考 [documentation](https://ibm.github.io/watson-machine-learning-sdk/)."]},{"cell_type":"code","execution_count":5,"metadata":{"pycharm":{"name":"#%%\n"}},"outputs":[],"source":["from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams\n","from ibm_watson_machine_learning.foundation_models.utils.enums import DecodingMethods\n","\n","parameters = {\n","    GenParams.DECODING_METHOD: DecodingMethods.SAMPLE,\n","    GenParams.MAX_NEW_TOKENS: 100,\n","    GenParams.MIN_NEW_TOKENS: 1,\n","    GenParams.TEMPERATURE: 0.5,\n","    GenParams.TOP_K: 50,\n","    GenParams.TOP_P: 1\n","}"]},{"cell_type":"markdown","metadata":{},"source":["### 初始化模型\n","用之前定義的參數初始化 `Model` 類別。"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["from ibm_watson_machine_learning.foundation_models import Model\n","\n","flan_ul2_model = Model(\n","    model_id=model_id_1, \n","    params=parameters, \n","    credentials=credentials,\n","    project_id=project_id)\n","\n","flan_t5_model = Model(\n","    model_id=model_id_2,\n","    credentials=credentials,\n","    project_id=project_id)"]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"}},"source":["<a id=\"watsonxllm\"></a>\n","## LangChain集成\n","\n","`WatsonxLLM` 封裝 watsonx.ai模型，提供模型的鏈集成。\n","\n","**操作:** 更多關於`CustomLLM`可參考 [LangChain documentation](https://python.langchain.com/docs/modules/model_io/models/llms/custom_llm)\n","\n","\n","### 初始化 `WatsonxLLM` 類"]},{"cell_type":"code","execution_count":7,"metadata":{"pycharm":{"name":"#%%\n"}},"outputs":[],"source":["from ibm_watson_machine_learning.foundation_models.extensions.langchain import WatsonxLLM\n","\n","flan_ul2_llm = flan_ul2_model.to_langchain()\n","flan_t5_llm = flan_t5_model.to_langchain()"]},{"cell_type":"markdown","metadata":{},"source":["**提示:** 如果需要將watsonx.ai模型與LangChain的Chain介面結合使用，請呼叫`model.to_langchain()`方法。會回傳 `WatsonxLLM`類，與LangChain CustomLLM 要求相容。"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/plain":["WatsonxLLM(model=<ibm_watson_machine_learning.foundation_models.model.Model object at 0x7f1f2dc05b70>)"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["flan_ul2_model.to_langchain()"]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"}},"source":["使用`dict()`方法，秀出所有WatsonxLLM物件中定義的資料。"]},{"cell_type":"code","execution_count":8,"metadata":{"pycharm":{"name":"#%%\n"}},"outputs":[{"data":{"text/plain":["{'model_id': 'google/flan-ul2',\n"," 'params': {'decoding_method': <DecodingMethods.SAMPLE: 'sample'>,\n","  'max_new_tokens': 100,\n","  'min_new_tokens': 1,\n","  'temperature': 0.5,\n","  'top_k': 50,\n","  'top_p': 1},\n"," 'project_id': '3543304f-de31-4458-8f2a-a31ceac23f79',\n"," 'space_id': None,\n"," '_type': 'IBM watsonx.ai'}"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["flan_ul2_llm.dict()"]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"}},"source":["<a id=\"experiment\"></a>\n","## Simple Sequential Chain實驗\n","最簡單的sequential chain類型是 `SimpleSequentialChain`, 其中每個步驟都有一個輸入和輸出，上一個步驟的輸出會作為下一個步驟的輸入。\n","\n","該實驗將包括產生一個關於任何主題的隨機問題並回答該問題。"]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"}},"source":["`PromptTemplate`物件透過使用者輸入、附加非靜態資料和固定模板字串的組合來幫助產生提示。\n","\n","在我們的例子中，我們想要建立兩個`PromptTemplate`對象，分別用於負責建立一個隨機問題並回答它。"]},{"cell_type":"code","execution_count":9,"metadata":{"pycharm":{"name":"#%%\n"}},"outputs":[],"source":["from langchain import PromptTemplate\n","\n","prompt_1 = PromptTemplate(\n","    input_variables=[\"topic\"], \n","    template=\"Generate a random question about {topic}: Question: \"\n",")\n","prompt_2 = PromptTemplate(\n","    input_variables=[\"question\"],\n","    template=\"Answer the following question: {question}\",\n",")"]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"}},"source":["我們希望使用「LLMChain」添加語言模型的功能.\n","\n","`prompt_to_flan_ul2` 鏈規定了提示模板的格式，其任務是產生隨機問題，將字串傳遞給LLM並傳回LLM輸出。"]},{"cell_type":"markdown","metadata":{},"source":["**提示:** 如果需要將watsonx.ai模型與LangChain的Chain介面結合使用，請呼叫`model.to_langchain()`方法。會回傳 `WatsonxLLM`類，與LangChain CustomLLM 要求相容。"]},{"cell_type":"code","execution_count":13,"metadata":{"pycharm":{"name":"#%%\n"}},"outputs":[],"source":["from langchain.chains import LLMChain\n","\n","prompt_to_flan_ul2 = LLMChain(llm=flan_ul2_model.to_langchain(), prompt=prompt_1)"]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"}},"source":["`flan_to_t5` 鏈規定了提示模版的格式，其任務是回答我們從`prompt_to_flan_ul2`鏈得到的問題, 將字串傳遞給LLM並返回LLM輸出。"]},{"cell_type":"code","execution_count":14,"metadata":{"pycharm":{"name":"#%%\n"}},"outputs":[],"source":["flan_to_t5 = LLMChain(llm=flan_t5_model.to_langchain(), prompt=prompt_2)"]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"}},"source":["這是完整的鏈，我們運行 `prompt_to_flan_ul2` 和 `flan_to_t5` 按序列組成的鏈."]},{"cell_type":"code","execution_count":null,"metadata":{"pycharm":{"name":"#%%\n"}},"outputs":[],"source":["from langchain.chains import SimpleSequentialChain\n","\n","qa = SimpleSequentialChain(chains=[prompt_to_flan_ul2, flan_to_t5], verbose=True)"]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"}},"source":["產生關於某個話題的隨機問題並回答。"]},{"cell_type":"code","execution_count":16,"metadata":{"pycharm":{"name":"#%%\n"}},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n","\u001b[36;1m\u001b[1;3mWhat is the most common car rental agency in the US?\u001b[0m\n","\u001b[33;1m\u001b[1;3malamo\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"data":{"text/plain":["'alamo'"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["qa.run('car rental')"]},{"cell_type":"markdown","metadata":{},"source":["## 產生中文話題的隨機問題並回答"]},{"cell_type":"code","execution_count":150,"metadata":{},"outputs":[],"source":["parameters_pt1 = {\n","    GenParams.DECODING_METHOD: DecodingMethods.GREEDY,\n","    GenParams.STOP_SEQUENCES: ['\\n'],\n","    GenParams.MAX_NEW_TOKENS: 100,\n","    GenParams.MIN_NEW_TOKENS: 1\n","}\n","\n","parameters_pt2 = {\n","    GenParams.DECODING_METHOD: DecodingMethods.GREEDY,\n","    GenParams.MAX_NEW_TOKENS: 100,\n","    GenParams.MIN_NEW_TOKENS: 1\n","}\n","\n","llama2_model_pt1 = Model(\n","    model_id=ModelTypes.LLAMA_2_70B_CHAT, \n","    params=parameters_pt1, \n","    credentials=credentials,\n","    project_id=project_id)\n","\n","llama2_model_pt2 = Model(\n","    model_id=ModelTypes.LLAMA_2_70B_CHAT, \n","    params=parameters_pt2, \n","    credentials=credentials,\n","    project_id=project_id)"]},{"cell_type":"code","execution_count":151,"metadata":{},"outputs":[],"source":["from langchain import PromptTemplate\n","\n","prompt_1 = PromptTemplate(\n","    input_variables=[\"topic\"], \n","    template=\"\"\"產生1個與{topic}相關的問題：\n","    問題：\n","    \"\"\"\n",")\n","prompt_2 = PromptTemplate(\n","    input_variables=[\"question\"],\n","    template=\"\"\"用1句話回答下列問題：\n","    問題：{question}\n","    答案： \"\"\"\n",")"]},{"cell_type":"code","execution_count":152,"metadata":{},"outputs":[],"source":["prompt_to_llama2 = LLMChain(llm=llama2_model_pt1.to_langchain(), prompt=prompt_1)\n","llama2_to_llama2 = LLMChain(llm=llama2_model_pt2.to_langchain(), prompt=prompt_2)"]},{"cell_type":"code","execution_count":153,"metadata":{},"outputs":[],"source":["qa = SimpleSequentialChain(chains=[prompt_to_llama2, llama2_to_llama2], verbose=True)"]},{"cell_type":"code","execution_count":157,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n","\u001b[36;1m\u001b[1;3m我想租一辆车，但是我不知道哪些租车公司可以在我所在的城市提供服务，也不知道它们的价格和质量是怎样的。\n","\u001b[0m\n","\u001b[33;1m\u001b[1;3m可以在网上搜索“租车公司 + 你所在的城市”，或者咨询当地旅游信息中心或朋友圈，了解不同租车公司的价格和质量，并且可以预订在线或者通过电话\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"data":{"text/plain":["'可以在网上搜索“租车公司 + 你所在的城市”，或者咨询当地旅游信息中心或朋友圈，了解不同租车公司的价格和质量，并且可以预订在线或者通过电话'"]},"execution_count":157,"metadata":{},"output_type":"execute_result"}],"source":["qa.run('租車')"]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"}},"source":["<a id=\"summary\"></a>\n","## 總結和下一步\n","\n","你順利地完成了這篇notebook!\n"," \n","你學習如何透過custom llm WastonxLLM使用Simple Squential Chain。\n"," \n","Check out our _[Online Documentation](https://ibm.github.io/watson-machine-learning-sdk/samples.html)_ for more samples, tutorials, documentation, how-tos, and blog posts. "]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"}},"source":["### Authors: \n"," **Mateusz Szewczyk**, Software Engineer at Watson Machine Learning."]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"}},"source":["Copyright © 2023 IBM. This notebook and its source code are released under the terms of the MIT License."]}],"metadata":{"kernelspec":{"display_name":"Python 3.10","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"}},"nbformat":4,"nbformat_minor":2}
